<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>torch on Even - A super concise theme for Hugo</title>
    <link>http://KiteYN.github.io/tags/torch/</link>
    <description>Recent content in torch on Even - A super concise theme for Hugo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 Sep 2022 22:51:34 +0800</lastBuildDate><atom:link href="http://KiteYN.github.io/tags/torch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nvidia驱动、CUDA安装版本基本概念</title>
      <link>http://KiteYN.github.io/tech/cuda%E9%A9%B1%E5%8A%A8/</link>
      <pubDate>Mon, 19 Sep 2022 22:51:34 +0800</pubDate>
      
      <guid>http://KiteYN.github.io/tech/cuda%E9%A9%B1%E5%8A%A8/</guid>
      <description>CUDA安装基本概念入门 一、背景 1 2 3 4 &amp;gt;&amp;gt;&amp;gt; torc.cuda.is_available() /home/slyang/.conda/envs/nlp/lib/python3.7/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 101: invalid device ordinal (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.) return torch._C._cuda_getDeviceCount() &amp;gt; 0 False 省流，最终解决方案：</description>
    </item>
    
  </channel>
</rss>
